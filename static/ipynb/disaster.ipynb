{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "disaster.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "nteract": {
      "version": "0.11.2"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUVgL1wNNajZ",
        "outputId": "033ee09a-64d8-40c8-a558-15eac14c80e2"
      },
      "source": [
        "import os\n",
        "\n",
        "spark_version = 'spark-3.0.1'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to cloud.r-project.org] [Conn\r0% [1 InRelease gpgv 88.7 kB] [Connecting to archive.ubuntu.com] [Connecting to\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Connecting to archive.ubuntu.com (91.189.88.142)\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Connecting to archive.ubuntu.com (91.189.88.142)\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le1oJYClz5GR"
      },
      "source": [
        "# Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"NaiveBayes\").getOrCreate()"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnI0zdY5NYCJ",
        "outputId": "b3efd65f-b15b-4102-b3c0-c22dba7e9b97"
      },
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url =\"https://raw.githubusercontent.com/choushuiguo325/disaster_tweets_ML/master/Resources/train_test.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"train_test.csv\"), sep=\",\", header=True)\n",
        "# Show DataFrame\n",
        "df.show()"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-------+--------+--------------------+------+--------+\n",
            "| id|keyword|location|                text|target|   class|\n",
            "+---+-------+--------+--------------------+------+--------+\n",
            "|  1|   null|    null|Our Deeds are the...|     1|positive|\n",
            "|  4|   null|    null|Forest fire near ...|     1|positive|\n",
            "|  5|   null|    null|All residents ask...|     1|positive|\n",
            "|  6|   null|    null|13,000 people rec...|     1|positive|\n",
            "|  7|   null|    null|Just got sent thi...|     1|positive|\n",
            "|  8|   null|    null|#RockyFire Update...|     1|positive|\n",
            "| 10|   null|    null|#flood #disaster ...|     1|positive|\n",
            "| 13|   null|    null|I'm on top of the...|     1|positive|\n",
            "| 14|   null|    null|There's an emerge...|     1|positive|\n",
            "| 15|   null|    null|I'm afraid that t...|     1|positive|\n",
            "| 16|   null|    null|Three people died...|     1|positive|\n",
            "| 17|   null|    null|Haha South Tampa ...|     1|positive|\n",
            "| 18|   null|    null|#raining #floodin...|     1|positive|\n",
            "| 19|   null|    null|#Flood in Bago My...|     1|positive|\n",
            "| 20|   null|    null|Damage to school ...|     1|positive|\n",
            "| 23|   null|    null|      What's up man?|     0|negative|\n",
            "| 24|   null|    null|       I love fruits|     0|negative|\n",
            "| 25|   null|    null|    Summer is lovely|     0|negative|\n",
            "| 26|   null|    null|   My car is so fast|     0|negative|\n",
            "| 28|   null|    null|What a goooooooaa...|     0|negative|\n",
            "+---+-------+--------+--------------------+------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BbzYExyNYCR",
        "outputId": "3ce8d9f6-e65e-4a5a-94da-f2002f86a6b7"
      },
      "source": [
        "import re\n",
        "from pyspark.sql.functions import length, regexp_replace, udf\n",
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "# Remove the punctuations in text\n",
        "puncRep = udf(lambda x: re.sub(r'[^\\w\\s]', '',x) )\n",
        "df = df.withColumn('cleaned',puncRep('text'))\n",
        "\n",
        "# Create a length column to be used as a future feature \n",
        "data_df = df.withColumn('length', length(df['cleaned']))\n",
        "data_df = data_df.withColumn(\"target\", data_df[\"target\"].cast(IntegerType()))\n",
        "data_df = data_df.withColumnRenamed(\"target\", \"label\")\n",
        "data_df.show()"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-------+--------+--------------------+-----+--------+--------------------+------+\n",
            "| id|keyword|location|                text|label|   class|             cleaned|length|\n",
            "+---+-------+--------+--------------------+-----+--------+--------------------+------+\n",
            "|  1|   null|    null|Our Deeds are the...|    1|positive|Our Deeds are the...|    68|\n",
            "|  4|   null|    null|Forest fire near ...|    1|positive|Forest fire near ...|    37|\n",
            "|  5|   null|    null|All residents ask...|    1|positive|All residents ask...|   130|\n",
            "|  6|   null|    null|13,000 people rec...|    1|positive|13000 people rece...|    63|\n",
            "|  7|   null|    null|Just got sent thi...|    1|positive|Just got sent thi...|    86|\n",
            "|  8|   null|    null|#RockyFire Update...|    1|positive|RockyFire Update ...|   103|\n",
            "| 10|   null|    null|#flood #disaster ...|    1|positive|flood disaster He...|    92|\n",
            "| 13|   null|    null|I'm on top of the...|    1|positive|Im on top of the ...|    55|\n",
            "| 14|   null|    null|There's an emerge...|    1|positive|Theres an emergen...|    78|\n",
            "| 15|   null|    null|I'm afraid that t...|    1|positive|Im afraid that th...|    48|\n",
            "| 16|   null|    null|Three people died...|    1|positive|Three people died...|    43|\n",
            "| 17|   null|    null|Haha South Tampa ...|    1|positive|Haha South Tampa ...|   127|\n",
            "| 18|   null|    null|#raining #floodin...|    1|positive|raining flooding ...|    69|\n",
            "| 19|   null|    null|#Flood in Bago My...|    1|positive|Flood in Bago Mya...|    37|\n",
            "| 20|   null|    null|Damage to school ...|    1|positive|Damage to school ...|    55|\n",
            "| 23|   null|    null|      What's up man?|    0|negative|        Whats up man|    12|\n",
            "| 24|   null|    null|       I love fruits|    0|negative|       I love fruits|    13|\n",
            "| 25|   null|    null|    Summer is lovely|    0|negative|    Summer is lovely|    16|\n",
            "| 26|   null|    null|   My car is so fast|    0|negative|   My car is so fast|    17|\n",
            "| 28|   null|    null|What a goooooooaa...|    0|negative|What a goooooooaa...|    22|\n",
            "+---+-------+--------+--------------------+-----+--------+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if3tRnOf6Nvv",
        "outputId": "6a0e0190-ab77-483a-8b61-caf261ddf766"
      },
      "source": [
        "# data_df_modified = data_df[['class','cleaned','length']]\n",
        "data_df_modified = data_df[['label','cleaned','length']]\n",
        "data_df_modified.show()"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------------------+------+\n",
            "|label|             cleaned|length|\n",
            "+-----+--------------------+------+\n",
            "|    1|Our Deeds are the...|    68|\n",
            "|    1|Forest fire near ...|    37|\n",
            "|    1|All residents ask...|   130|\n",
            "|    1|13000 people rece...|    63|\n",
            "|    1|Just got sent thi...|    86|\n",
            "|    1|RockyFire Update ...|   103|\n",
            "|    1|flood disaster He...|    92|\n",
            "|    1|Im on top of the ...|    55|\n",
            "|    1|Theres an emergen...|    78|\n",
            "|    1|Im afraid that th...|    48|\n",
            "|    1|Three people died...|    43|\n",
            "|    1|Haha South Tampa ...|   127|\n",
            "|    1|raining flooding ...|    69|\n",
            "|    1|Flood in Bago Mya...|    37|\n",
            "|    1|Damage to school ...|    55|\n",
            "|    0|        Whats up man|    12|\n",
            "|    0|       I love fruits|    13|\n",
            "|    0|    Summer is lovely|    16|\n",
            "|    0|   My car is so fast|    17|\n",
            "|    0|What a goooooooaa...|    22|\n",
            "+-----+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sbWIAL8zn_p"
      },
      "source": [
        "# df = spark.createDataFrame([\n",
        "#     (1,\"positive\", \"####Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\"),\n",
        "#     (2,\"negative\", \"!Forest fire near La Ronge Sask. Canada\"),\n",
        "#     (3,\"negative\", \"All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\"),\n",
        "#     (4,\"positive\", \"??13,000 people receive #wildfires evacuation orders in California .\"),\n",
        "#     (5,\"positive\", \"!Mango juice with crushed ice&gt;&gt;&gt;&gt;??\"),\n",
        "#     (6,\"negative\", \"#RockyFire Update => California Hwy. 20 closed in both directions due to Lake County fire - #CAfire #wildfires\")\n",
        "# ],[\"id\",\"class\", \"text\"])\n",
        "\n",
        "# from pyspark.sql.functions import length\n",
        "# data_df = df.withColumn('text',)\n",
        "# # Create a length column to be used as a future feature \n",
        "# data_df = df.withColumn('length', length(df['text']))\n",
        "# data_df.show()\n",
        "\n",
        "# data_df_modified = data_df[['class','text','length']]\n",
        "# data_df_modified.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFF6RWCfBZrp"
      },
      "source": [
        "# data_df_modified = data_df[['class','text','length']]\n",
        "# data_df_modified.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od7Qj0sxNYCW"
      },
      "source": [
        "### Feature Transformations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59dwxefsNYCX"
      },
      "source": [
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
        "# Create all the features to the data set\n",
        "# pos_neg_to_num = StringIndexer(inputCol='class',outputCol='label')\n",
        "tokenizer = Tokenizer(inputCol=\"cleaned\", outputCol=\"token_text\")\n",
        "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
        "hashingTF = HashingTF(inputCol=\"stop_tokens\", outputCol='hash_token')\n",
        "idf = IDF(inputCol='hash_token', outputCol='idf_token')"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yssO0_Q5NYCb"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector\n",
        "\n",
        "# Create feature vectors\n",
        "clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_YyUpR3NYCf"
      },
      "source": [
        "# Create a and run a data processing Pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "# data_prep_pipeline = Pipeline(stages=[pos_neg_to_num, tokenizer, stopremove, hashingTF, idf, clean_up])\n",
        "data_prep_pipeline = Pipeline(stages=[tokenizer, stopremove, hashingTF, idf, clean_up])"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBViHQOaNYCj",
        "outputId": "53f60eda-7cb1-4eef-8e4d-07eed8366cda"
      },
      "source": [
        "# Fit and transform the pipeline\n",
        "cleaner = data_prep_pipeline.fit(data_df_modified)\n",
        "cleaned = cleaner.transform(data_df_modified)\n",
        "cleaned.show()"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|label|             cleaned|length|          token_text|         stop_tokens|          hash_token|           idf_token|            features|\n",
            "+-----+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|    1|Our Deeds are the...|    68|[our, deeds, are,...|[deeds, reason, e...|(262144,[24370,68...|(262144,[24370,68...|(262145,[24370,68...|\n",
            "|    1|Forest fire near ...|    37|[forest, fire, ne...|[forest, fire, ne...|(262144,[55310,91...|(262144,[55310,91...|(262145,[55310,91...|\n",
            "|    1|All residents ask...|   130|[all, residents, ...|[residents, asked...|(262144,[38983,41...|(262144,[38983,41...|(262145,[38983,41...|\n",
            "|    1|13000 people rece...|    63|[13000, people, r...|[13000, people, r...|(262144,[38983,39...|(262144,[38983,39...|(262145,[38983,39...|\n",
            "|    1|Just got sent thi...|    86|[just, got, sent,...|[got, sent, photo...|(262144,[39441,52...|(262144,[39441,52...|(262145,[39441,52...|\n",
            "|    1|RockyFire Update ...|   103|[rockyfire, updat...|[rockyfire, updat...|(262144,[7588,394...|(262144,[7588,394...|(262145,[7588,394...|\n",
            "|    1|flood disaster He...|    92|[flood, disaster,...|[flood, disaster,...|(262144,[1797,163...|(262144,[1797,163...|(262145,[1797,163...|\n",
            "|    1|Im on top of the ...|    55|[im, on, top, of,...|[im, top, hill, s...|(262144,[4106,853...|(262144,[4106,853...|(262145,[4106,853...|\n",
            "|    1|Theres an emergen...|    78|[theres, an, emer...|[theres, emergenc...|(262144,[38983,70...|(262144,[38983,70...|(262145,[38983,70...|\n",
            "|    1|Im afraid that th...|    48|[im, afraid, that...|[im, afraid, torn...|(262144,[12409,31...|(262144,[12409,31...|(262145,[12409,31...|\n",
            "|    1|Three people died...|    43|[three, people, d...|[three, people, d...|(262144,[59791,96...|(262144,[59791,96...|(262145,[59791,96...|\n",
            "|    1|Haha South Tampa ...|   127|[haha, south, tam...|[haha, south, tam...|(262144,[33053,59...|(262144,[33053,59...|(262145,[33053,59...|\n",
            "|    1|raining flooding ...|    69|[raining, floodin...|[raining, floodin...|(262144,[19153,24...|(262144,[19153,24...|(262145,[19153,24...|\n",
            "|    1|Flood in Bago Mya...|    37|[flood, in, bago,...|[flood, bago, mya...|(262144,[16319,77...|(262144,[16319,77...|(262145,[16319,77...|\n",
            "|    1|Damage to school ...|    55|[damage, to, scho...|[damage, school, ...|(262144,[12826,27...|(262144,[12826,27...|(262145,[12826,27...|\n",
            "|    0|        Whats up man|    12|    [whats, up, man]|        [whats, man]|(262144,[48531,10...|(262144,[48531,10...|(262145,[48531,10...|\n",
            "|    0|       I love fruits|    13|   [i, love, fruits]|      [love, fruits]|(262144,[186480,2...|(262144,[186480,2...|(262145,[186480,2...|\n",
            "|    0|    Summer is lovely|    16|[summer, is, lovely]|    [summer, lovely]|(262144,[167401,1...|(262144,[167401,1...|(262145,[167401,1...|\n",
            "|    0|   My car is so fast|    17|[my, car, is, so,...|         [car, fast]|(262144,[71578,11...|(262144,[71578,11...|(262145,[71578,11...|\n",
            "|    0|What a goooooooaa...|    22|[what, a, goooooo...|   [goooooooaaaaaal]|(262144,[195910],...|(262144,[195910],...|(262145,[195910,2...|\n",
            "+-----+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaKPFYeSGM8y",
        "outputId": "33b7b045-a14c-45a3-9345-4e3afdf6ea74"
      },
      "source": [
        "data_df_modified.show()"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------------------+------+\n",
            "|label|             cleaned|length|\n",
            "+-----+--------------------+------+\n",
            "|    1|Our Deeds are the...|    68|\n",
            "|    1|Forest fire near ...|    37|\n",
            "|    1|All residents ask...|   130|\n",
            "|    1|13000 people rece...|    63|\n",
            "|    1|Just got sent thi...|    86|\n",
            "|    1|RockyFire Update ...|   103|\n",
            "|    1|flood disaster He...|    92|\n",
            "|    1|Im on top of the ...|    55|\n",
            "|    1|Theres an emergen...|    78|\n",
            "|    1|Im afraid that th...|    48|\n",
            "|    1|Three people died...|    43|\n",
            "|    1|Haha South Tampa ...|   127|\n",
            "|    1|raining flooding ...|    69|\n",
            "|    1|Flood in Bago Mya...|    37|\n",
            "|    1|Damage to school ...|    55|\n",
            "|    0|        Whats up man|    12|\n",
            "|    0|       I love fruits|    13|\n",
            "|    0|    Summer is lovely|    16|\n",
            "|    0|   My car is so fast|    17|\n",
            "|    0|What a goooooooaa...|    22|\n",
            "+-----+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPWvpZXW_2Ym"
      },
      "source": [
        "# cleaned.rdd.map(lambda x: (x.stop_tokens))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDODyxF7NYCn",
        "outputId": "657aa87b-81fd-4c42-9db4-ccb39615a2b3"
      },
      "source": [
        "# Show label and resulting features\n",
        "cleaned.select(['label', 'features']).show()"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|    1|(262145,[24370,68...|\n",
            "|    1|(262145,[55310,91...|\n",
            "|    1|(262145,[38983,41...|\n",
            "|    1|(262145,[38983,39...|\n",
            "|    1|(262145,[39441,52...|\n",
            "|    1|(262145,[7588,394...|\n",
            "|    1|(262145,[1797,163...|\n",
            "|    1|(262145,[4106,853...|\n",
            "|    1|(262145,[38983,70...|\n",
            "|    1|(262145,[12409,31...|\n",
            "|    1|(262145,[59791,96...|\n",
            "|    1|(262145,[33053,59...|\n",
            "|    1|(262145,[19153,24...|\n",
            "|    1|(262145,[16319,77...|\n",
            "|    1|(262145,[12826,27...|\n",
            "|    0|(262145,[48531,10...|\n",
            "|    0|(262145,[186480,2...|\n",
            "|    0|(262145,[167401,1...|\n",
            "|    0|(262145,[71578,11...|\n",
            "|    0|(262145,[195910,2...|\n",
            "+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzfCQmrVNYCr"
      },
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "# Break data down into a training set and a testing set\n",
        "training, testing = cleaned.randomSplit([0.7, 0.3])\n",
        "\n",
        "# Create a Naive Bayes model and fit training data\n",
        "nb = NaiveBayes()\n",
        "predictor = nb.fit(training)"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EG-xOqKsCcGX",
        "outputId": "303f5ba8-b498-4605-e2a3-81ef314efd49"
      },
      "source": [
        "training.show()\n",
        "training.filter(training['label']==1).count()"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|label|             cleaned|length|          token_text|         stop_tokens|          hash_token|           idf_token|            features|\n",
            "+-----+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|    0|   Do you like pasta|    17|[do, you, like, p...|       [like, pasta]|(262144,[208258,2...|(262144,[208258,2...|(262145,[208258,2...|\n",
            "|    0|            LOOOOOOL|     8|          [looooool]|          [looooool]|(262144,[12268],[...|(262144,[12268],[...|(262145,[12268,26...|\n",
            "|    0|     London is cool |    15|  [london, is, cool]|      [london, cool]|(262144,[223619,2...|(262144,[223619,2...|(262145,[223619,2...|\n",
            "|    0|  Love my girlfriend|    18|[love, my, girlfr...|  [love, girlfriend]|(262144,[121169,1...|(262144,[121169,1...|(262145,[121169,1...|\n",
            "|    0|         Love skiing|    11|      [love, skiing]|      [love, skiing]|(262144,[173426,1...|(262144,[173426,1...|(262145,[173426,1...|\n",
            "|    0|    Summer is lovely|    16|[summer, is, lovely]|    [summer, lovely]|(262144,[167401,1...|(262144,[167401,1...|(262145,[167401,1...|\n",
            "|    0|             The end|     7|          [the, end]|               [end]|(262144,[156917],...|(262144,[156917],...|(262145,[156917,2...|\n",
            "|    0|We always try to ...|    59|[we, always, try,...|[always, try, bri...|(262144,[1797,774...|(262144,[1797,774...|(262145,[1797,774...|\n",
            "|    0|What a goooooooaa...|    22|[what, a, goooooo...|   [goooooooaaaaaal]|(262144,[195910],...|(262144,[195910],...|(262145,[195910,2...|\n",
            "|    0|What a wonderful day|    20|[what, a, wonderf...|    [wonderful, day]|(262144,[15585,25...|(262144,[15585,25...|(262145,[15585,25...|\n",
            "|    0|        Whats up man|    12|    [whats, up, man]|        [whats, man]|(262144,[48531,10...|(262144,[48531,10...|(262145,[48531,10...|\n",
            "|    0|  this is ridiculous|    18|[this, is, ridicu...|        [ridiculous]|(262144,[32235],[...|(262144,[32235],[...|(262145,[32235,26...|\n",
            "|    1|AFRICANBAZE Break...|    73|[africanbaze, bre...|[africanbaze, bre...|(262144,[27544,95...|(262144,[27544,95...|(262145,[27544,95...|\n",
            "|    1|Damage to school ...|    55|[damage, to, scho...|[damage, school, ...|(262144,[12826,27...|(262144,[12826,27...|(262145,[12826,27...|\n",
            "|    1|Forest fire near ...|    37|[forest, fire, ne...|[forest, fire, ne...|(262144,[55310,91...|(262144,[55310,91...|(262145,[55310,91...|\n",
            "|    1|Haha South Tampa ...|   127|[haha, south, tam...|[haha, south, tam...|(262144,[33053,59...|(262144,[33053,59...|(262145,[33053,59...|\n",
            "|    1|Just got sent thi...|    86|[just, got, sent,...|[got, sent, photo...|(262144,[39441,52...|(262144,[39441,52...|(262145,[39441,52...|\n",
            "|    1|Our Deeds are the...|    68|[our, deeds, are,...|[deeds, reason, e...|(262144,[24370,68...|(262144,[24370,68...|(262145,[24370,68...|\n",
            "|    1|RockyFire Update ...|   103|[rockyfire, updat...|[rockyfire, updat...|(262144,[7588,394...|(262144,[7588,394...|(262145,[7588,394...|\n",
            "|    1|Theres an emergen...|    78|[theres, an, emer...|[theres, emergenc...|(262144,[38983,70...|(262144,[38983,70...|(262145,[38983,70...|\n",
            "+-----+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeckHhg5NYCv",
        "outputId": "38bd99b0-b0fd-462d-daa3-4b4e572412dc"
      },
      "source": [
        "# Tranform the model with the testing data\n",
        "test_results = predictor.transform(testing)\n",
        "test_results.show(5)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|label|             cleaned|length|          token_text|         stop_tokens|          hash_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n",
            "+-----+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|    0|             Cooool |     7|            [cooool]|            [cooool]|(262144,[43292],[...|(262144,[43292],[...|(262145,[43292,26...|[-86.182207144436...|[1.08979306084503...|       1.0|\n",
            "|    0|Crying out for mo...|    33|[crying, out, for...|[crying, set, abl...|(262144,[151657,2...|(262144,[151657,2...|(262145,[151657,2...|[-328.32404539489...|[1.68322802418822...|       1.0|\n",
            "|    0|       I love fruits|    13|   [i, love, fruits]|      [love, fruits]|(262144,[186480,2...|(262144,[186480,2...|(262145,[186480,2...|[-152.29229205650...|[1.65553993250883...|       1.0|\n",
            "|    0|   My car is so fast|    17|[my, car, is, so,...|         [car, fast]|(262144,[71578,11...|(262144,[71578,11...|(262145,[71578,11...|[-187.84956429615...|[9.49087496864002...|       1.0|\n",
            "|    0|No wayI cant eat ...|    26|[no, wayi, cant, ...|[wayi, cant, eat,...|(262144,[64076,18...|(262144,[64076,18...|(262145,[64076,18...|[-328.63479743095...|[1.54355019234749...|       1.0|\n",
            "+-----+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKTQKmr6aVxg",
        "outputId": "fa34a268-18ed-4671-ea0d-68cbd59f8d13"
      },
      "source": [
        "print(\"test size\",test_results.count())\n",
        "test_results.show()"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test size 12\n",
            "+-----+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|label|             cleaned|length|          token_text|         stop_tokens|          hash_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n",
            "+-----+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|    0|             Cooool |     7|            [cooool]|            [cooool]|(262144,[43292],[...|(262144,[43292],[...|(262145,[43292,26...|[-86.182207144436...|[1.08979306084503...|       1.0|\n",
            "|    0|Crying out for mo...|    33|[crying, out, for...|[crying, set, abl...|(262144,[151657,2...|(262144,[151657,2...|(262145,[151657,2...|[-328.32404539489...|[1.68322802418822...|       1.0|\n",
            "|    0|       I love fruits|    13|   [i, love, fruits]|      [love, fruits]|(262144,[186480,2...|(262144,[186480,2...|(262145,[186480,2...|[-152.29229205650...|[1.65553993250883...|       1.0|\n",
            "|    0|   My car is so fast|    17|[my, car, is, so,...|         [car, fast]|(262144,[71578,11...|(262144,[71578,11...|(262145,[71578,11...|[-187.84956429615...|[9.49087496864002...|       1.0|\n",
            "|    0|No wayI cant eat ...|    26|[no, wayi, cant, ...|[wayi, cant, eat,...|(262144,[64076,18...|(262144,[64076,18...|(262145,[64076,18...|[-328.63479743095...|[1.54355019234749...|       1.0|\n",
            "|    0|Was in NYC last week|    20|[was, in, nyc, la...|   [nyc, last, week]|(262144,[5381,132...|(262144,[5381,132...|(262145,[5381,132...|[-250.17264262620...|[4.11406069811885...|       1.0|\n",
            "|    1|13000 people rece...|    63|[13000, people, r...|[13000, people, r...|(262144,[38983,39...|(262144,[38983,39...|(262145,[38983,39...|[-665.80188513435...|[9.59953167754600...|       1.0|\n",
            "|    1|All residents ask...|   130|[all, residents, ...|[residents, asked...|(262144,[38983,41...|(262144,[38983,41...|(262145,[38983,41...|[-1302.2614515749...|[4.54120349325088...|       1.0|\n",
            "|    1|Flood in Bago Mya...|    37|[flood, in, bago,...|[flood, bago, mya...|(262144,[16319,77...|(262144,[16319,77...|(262145,[16319,77...|[-437.36828045496...|[3.60424944920985...|       1.0|\n",
            "|    1|Im afraid that th...|    48|[im, afraid, that...|[im, afraid, torn...|(262144,[12409,31...|(262144,[12409,31...|(262145,[12409,31...|[-515.09566505013...|[4.13314326193832...|       1.0|\n",
            "|    1|Im on top of the ...|    55|[im, on, top, of,...|[im, top, hill, s...|(262144,[4106,853...|(262144,[4106,853...|(262145,[4106,853...|[-591.97501329827...|[1.02259658609012...|       1.0|\n",
            "|    1|Three people died...|    43|[three, people, d...|[three, people, d...|(262144,[59791,96...|(262144,[59791,96...|(262145,[59791,96...|[-515.83043525970...|[3.00856427370959...|       1.0|\n",
            "+-----+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AN5GxMui0CGh",
        "outputId": "ecb5678b-cad2-4b1e-f187-eeef92d51538"
      },
      "source": [
        "right_prediction = test_results.filter(test_results['prediction'] == test_results['label']).count()\n",
        "tp = test_results.filter((test_results['prediction']== 1) & (test_results['label']== 1)).count()\n",
        "tn = test_results.filter((test_results['prediction']== 0) & (test_results['label']== 0)).count()\n",
        "fp = test_results.filter((test_results['prediction']== 1) & (test_results['label']== 0)).count()\n",
        "fn = test_results.filter((test_results['prediction']== 0) & (test_results['label']== 1)).count()\n",
        "\n",
        "confusionMatrix = spark.createDataFrame([\n",
        "    (1,\"predicton: P\", tp,fp),\n",
        "    (2,\"predicton: N\", fn,tn)\n",
        "], [\"id\",\"xixix\",\"actual: P\", \"actual: N\"])\n",
        "\n",
        "confusionMatrix.show()"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+------------+---------+---------+\n",
            "| id|       xixix|actual: P|actual: N|\n",
            "+---+------------+---------+---------+\n",
            "|  1|predicton: P|        6|        6|\n",
            "|  2|predicton: N|        0|        0|\n",
            "+---+------------+---------+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVFrWcHINYCz",
        "outputId": "276b4420-0b46-47ab-dbbc-0b002f4d4ed7"
      },
      "source": [
        "\n",
        "# # Use the Class Evaluator for a cleaner description\n",
        "# from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# acc_eval = MulticlassClassificationEvaluator()\n",
        "# acc = acc_eval.evaluate(test_results)\n",
        "# print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting reviews was: 0.333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOpKc638NlCQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79630706-f2fb-47e9-8843-d9ef73fe6e39"
      },
      "source": [
        "accuracy_eval = MulticlassClassificationEvaluator(metricName = 'accuracy')\n",
        "print(\"accuracy\",accuracy_eval.evaluate(test_results))"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "TC4scZnI2caK",
        "outputId": "9ee06191-d835-4471-da2e-5e3f5acdb735"
      },
      "source": [
        "# Compute raw scores on the test set\n",
        "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
        "predictionAndLabels = test_results.rdd.map(lambda lp: (lp.prediction, lp.label))\n",
        "\n",
        "# Instantiate metrics object\n",
        "metrics = BinaryClassificationMetrics(predictionAndLabels)\n",
        "# # Area under precision-recall curve\n",
        "# print(\"Area under PR = %s\" % metrics.areaUnderPR)\n",
        "\n",
        "# # Area under ROC curve\n",
        "# print(\"Area under ROC = %s\" % metrics.areaUnderROC)\n",
        "\n",
        "precision = metrics.precision()\n",
        "recall = metrics.recall()\n",
        "f1Score = metrics.fMeasure()\n",
        "print(\"Summary Stats\")\n",
        "print(\"Precision = %s\" % precision)\n",
        "print(\"Recall = %s\" % recall)\n",
        "print(\"F1 Score = %s\" % f1Score)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-168-7c0f6ddf5182>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# print(\"Area under ROC = %s\" % metrics.areaUnderROC)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mf1Score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfMeasure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'BinaryClassificationMetrics' object has no attribute 'precision'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgjSI_aq6V2C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}